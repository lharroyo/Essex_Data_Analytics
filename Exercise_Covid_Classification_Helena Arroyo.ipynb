{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise-Covid_Classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FluT1M9QvcvV",
        "outputId": "58a8ded8-cc08-4618-f573-80d0029dd429"
      },
      "source": [
        "!git clone https://github.com/UCSD-AI4H/COVID-CT.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'COVID-CT'...\n",
            "remote: Enumerating objects: 5463, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 5463 (delta 0), reused 1 (delta 0), pack-reused 5459\u001b[K\n",
            "Receiving objects: 100% (5463/5463), 1.09 GiB | 17.31 MiB/s, done.\n",
            "Resolving deltas: 100% (360/360), done.\n",
            "Checking out files: 100% (1048/1048), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbh1Nm2mv_cF"
      },
      "source": [
        "## unzip archives  q - quite, n - don't overwrite\n",
        "!unzip -q -n '/content/COVID-CT/Images-processed/CT_COVID.zip'\n",
        "!unzip -q -n '/content/COVID-CT/Images-processed/CT_NonCOVID.zip'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gV196flwWAH",
        "outputId": "2f559e1e-851f-40b1-9d10-747a48033aec"
      },
      "source": [
        "import os\n",
        "path='/content/CT_COVID/'\n",
        "for count, filename in enumerate(os.listdir(path)): \n",
        "    dst =\"covid-\" + str(count) + \".png\"\n",
        "    src =path+ filename \n",
        "    dst =path+ dst \n",
        "        \n",
        "    # rename() function will \n",
        "    # rename all the files \n",
        "    os.rename(src, dst)\n",
        "print(\"Covid Positive cases: \", count)\n",
        "\n",
        "path='/content/CT_NonCOVID/'\n",
        "for count, filename in enumerate(os.listdir(path)): \n",
        "    dst =\"noncovid-\" + str(count) + \".png\"\n",
        "    src =path+ filename \n",
        "    dst =path+ dst \n",
        "        \n",
        "    # rename() function will \n",
        "    # rename all the files \n",
        "    os.rename(src, dst)\n",
        "\n",
        "print(\"Covid Negative cases: \", count)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Covid Positive cases:  348\n",
            "Covid Negative cases:  396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise\n",
        "We have downlaoded the COVID Image Data for you. Now, please a train and build a classification model to detect COVID vs Non-Covid cases. "
      ],
      "metadata": {
        "id": "wpGcwbg9T4UO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/covid19_CT'\n",
        "if not os.path.exists(base_dir): os.mkdir(base_dir)"
      ],
      "metadata": {
        "id": "HRY5Dr7oFhix"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = os.path.join(base_dir, 'train')\n",
        "if not os.path.exists(train_dir): os.mkdir(train_dir)\n",
        "\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "if not os.path.exists(validation_dir):os.mkdir(validation_dir)\n",
        "\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "if not os.path.exists(test_dir):os.mkdir(test_dir)\n",
        "\n",
        "train_covid_dir = os.path.join(train_dir, 'covid')\n",
        "os.mkdir(train_covid_dir)\n",
        "\n",
        "train_noncovid_dir = os.path.join(train_dir, 'noncovid')\n",
        "os.mkdir(train_noncovid_dir)\n",
        "\n",
        "validation_covid_dir = os.path.join(validation_dir, 'covid')\n",
        "os.mkdir(validation_covid_dir)\n",
        "\n",
        "validation_noncovid_dir = os.path.join(validation_dir, 'noncovid')\n",
        "os.mkdir(validation_noncovid_dir)\n",
        "\n",
        "test_covid_dir = os.path.join(test_dir, 'covid')\n",
        "os.mkdir(test_covid_dir)\n",
        "\n",
        "test_noncovid_dir = os.path.join(test_dir, 'noncovid')\n",
        "os.mkdir(test_noncovid_dir)"
      ],
      "metadata": {
        "id": "BDkk1cS5F6Cc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_dataset_dir_covid = '/content/CT_COVID/'\n",
        "original_dataset_dir_non_covid = '/content/CT_NonCOVID/'\n",
        "\n",
        "import shutil\n",
        "fnames = ['covid-{}.png'.format(i) for i in range(250)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir_covid, fname)\n",
        "    dst = os.path.join(train_covid_dir, fname)\n",
        "    #print(src,dst)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "fnames = ['covid-{}.png'.format(i) for i in range(250, 300)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir_covid, fname)\n",
        "    dst = os.path.join(validation_covid_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['covid-{}.png'.format(i) for i in range(300, 348)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir_covid, fname)\n",
        "    dst = os.path.join(test_covid_dir, fname)\n",
        "    shutil.copyfile(src, dst)"
      ],
      "metadata": {
        "id": "z6TEq-lGFz1J"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fnames = ['noncovid-{}.png'.format(i) for i in range(300)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir_non_covid, fname)\n",
        "    dst = os.path.join(train_noncovid_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['noncovid-{}.png'.format(i) for i in range(300, 350)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir_non_covid, fname)\n",
        "    dst = os.path.join(validation_noncovid_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['noncovid-{}.png'.format(i) for i in range(350, 390)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir_non_covid, fname)\n",
        "    dst = os.path.join(test_noncovid_dir, fname)\n",
        "    shutil.copyfile(src, dst)"
      ],
      "metadata": {
        "id": "VVRagyBrF9tP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('total training covid images:', len(os.listdir(train_covid_dir)))\n",
        "print('total training noncovid images:', len(os.listdir(train_noncovid_dir)))\n",
        "print('total validation covid images:', len(os.listdir(validation_covid_dir)))\n",
        "print('total validation noncovidog images:', len(os.listdir(validation_noncovid_dir)))\n",
        "print('total test covid images:', len(os.listdir(validation_noncovid_dir)))\n",
        "print('total test noncovidog images:', len(os.listdir(test_noncovid_dir)))"
      ],
      "metadata": {
        "id": "-GOZJtHrQBze",
        "outputId": "35b72895-6bc8-4bc7-bbf9-dd759a65c285",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total training covid images: 250\n",
            "total training noncovid images: 300\n",
            "total validation covid images: 50\n",
            "total validation noncovidog images: 100\n",
            "total test covid images: 100\n",
            "total test noncovidog images: 88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "V7ZS43piQdsr",
        "outputId": "4286e618-c302-4dbe-a81d-ec21d9858625",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 74, 74, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 36, 36, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 17, 17, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 15, 15, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 7, 7, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               3211776   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,453,121\n",
            "Trainable params: 3,453,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import optimizers\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "id": "gyfmcD--QyIk",
        "outputId": "32b3fb1e-97e1-48d8-9d16-3302cb3c84a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(150, 150), \n",
        "                                                    batch_size=10,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
        "                                                        target_size=(150, 150),\n",
        "                                                        batch_size=10,\n",
        "                                                        class_mode='binary')\n",
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=30,\n",
        "                              epochs=7,\n",
        "                              validation_data=validation_generator,\n",
        "                              validation_steps=5)"
      ],
      "metadata": {
        "id": "hBiSkQRdQ20t",
        "outputId": "94276f26-da76-4316-e351-57cdf42430b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 550 images belonging to 2 classes.\n",
            "Found 150 images belonging to 2 classes.\n",
            "Epoch 1/7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30/30 [==============================] - 2s 56ms/step - loss: 0.5064 - acc: 0.7567 - val_loss: 0.5744 - val_acc: 0.6600\n",
            "Epoch 2/7\n",
            "30/30 [==============================] - 2s 57ms/step - loss: 0.4634 - acc: 0.7733 - val_loss: 0.5243 - val_acc: 0.7600\n",
            "Epoch 3/7\n",
            "30/30 [==============================] - 2s 57ms/step - loss: 0.4497 - acc: 0.8100 - val_loss: 0.4667 - val_acc: 0.7400\n",
            "Epoch 4/7\n",
            "30/30 [==============================] - 2s 59ms/step - loss: 0.4421 - acc: 0.7933 - val_loss: 0.5165 - val_acc: 0.8400\n",
            "Epoch 5/7\n",
            "30/30 [==============================] - 2s 54ms/step - loss: 0.4006 - acc: 0.8367 - val_loss: 0.4819 - val_acc: 0.7200\n",
            "Epoch 6/7\n",
            "30/30 [==============================] - 2s 55ms/step - loss: 0.4180 - acc: 0.8200 - val_loss: 0.5850 - val_acc: 0.7200\n",
            "Epoch 7/7\n",
            "30/30 [==============================] - 2s 55ms/step - loss: 0.3925 - acc: 0.8200 - val_loss: 0.3861 - val_acc: 0.9000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from random import shuffle\n",
        "\n",
        "IMG_SIZE = 224\n",
        "LR = 1e-4"
      ],
      "metadata": {
        "id": "cX1aAvTkF_uF"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_img(img):\n",
        "    word_label = img.split('-')[0]\n",
        "    if word_label == 'covid': return 1\n",
        "    elif word_label == 'noncovid': return 0"
      ],
      "metadata": {
        "id": "7w6eZwCKGCBP"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createDataSplitSet(datapath):\n",
        "    X=[]\n",
        "    y=[]\n",
        "\n",
        "    for img in os.listdir(datapath):\n",
        "        label = label_img(img)\n",
        "        path = os.path.join(datapath, img)\n",
        "        image = cv2.resize(cv2.imread(path), (IMG_SIZE, IMG_SIZE))\n",
        "        image = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "\n",
        "        X.append(np.array(image))\n",
        "        y.append(label)\n",
        "\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "bFDj9sIpGEY7"
      },
      "execution_count": 31,
      "outputs": []
    }
  ]
}